import ollama
import argparse
import random
from PIL import Image
import os
import torch
from diffusers import AutoPipelineForText2Image, StableVideoDiffusionPipeline
from diffusers.utils import export_to_video

# === –ê—Ä–≥—É–º–µ–Ω—Ç—ã ===
parser = argparse.ArgumentParser()
parser.add_argument('--generate-video', action='store_true', help='–í–∫–ª—é—á–∏—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≤–∏–¥–µ–æ (—Ç—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ VRAM)')
args = parser.parse_args()
# args.generate_video = True  # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ, —á—Ç–æ–±—ã –≤–∫–ª—é—á–∏—Ç—å

# === –¶–≤–µ—Ç–∞ ===
COLORS = {
    '–†–∞—Å—Å–∫–∞–∑—á–∏–∫': '\033[94m',
    '–†–µ–±—ë–Ω–æ–∫': '\033[92m',
    '–†–µ–¥–∞–∫—Ç–æ—Ä': '\033[93m',
    '–°–∫–∞–∑–∫–∞': '\033[95m',
    '–≠—Ç–∞–ø': '\033[1;97m',
    '–í–∏–¥–µ–æ': '\033[96m',
    'ENDC': '\033[0m'
}

# === –ú–æ–¥–µ–ª–∏ ===
print("üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
print("üé® –ó–∞–≥—Ä—É–∑–∫–∞ SDXL-Turbo...")
pipe_sdxl = AutoPipelineForText2Image.from_pretrained(
    "stabilityai/sdxl-turbo",
    torch_dtype=torch.float16,
    variant="fp16",
    use_safetensors=True
)
pipe_sdxl.to("cuda")

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ (XT)
pipe_svd = None
if args.generate_video:
    print("üé• –ó–∞–≥—Ä—É–∑–∫–∞ Stable Video Diffusion XT 1.1...")
    pipe_svd = StableVideoDiffusionPipeline.from_pretrained(
        "stabilityai/stable-video-diffusion-img2vid-xt-1-1",
        torch_dtype=torch.float16,
        variant="fp16"
    )
    pipe_svd.to("cuda")


# === –ê–≥–µ–Ω—Ç—ã —á–µ—Ä–µ–∑ Ollama ===
class Agent:
    def __init__(self, name, system_prompt, model="qwen:14b-chat-q4_K_M"):
        self.name = name
        self.system_prompt = system_prompt
        self.model = model

    def respond(self, prompt):
        response = ollama.generate(
            model=self.model,
            prompt=f"{self.system_prompt}\n\n{prompt}",
            options={
                'temperature': 0.6,
                'top_p': 0.95,
                'top_k': 30,
                'num_ctx': 8192
            }
        )
        return response['response'].strip()


# === –¢–µ–º–∞ –∏ —ç—Ç–∞–ø—ã ===
PLOT_TEMPLATES = [
    "–¶–∞—Ä–µ–≤–Ω—É –ø–æ—Ö–∏—Ç–∏–ª –∑–º–µ–π, –∏ –¥–æ–±—Ä—ã–π –º–æ–ª–æ–¥–µ—Ü –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –µ—ë —Å–ø–∞—Å–∞—Ç—å.",
    "–¶–∞—Ä—å –∑–∞–±–æ–ª–µ–ª ‚Äî –Ω—É–∂–Ω–∞ –∂–∏–≤–∞—è –≤–æ–¥–∞ –∑–∞ —Ç—Ä–∏–¥–µ–≤—è—Ç—å –∑–µ–º–µ–ª—å."
]
chosen_plot = random.choice(PLOT_TEMPLATES)
print(f"\n{COLORS['–≠—Ç–∞–ø']}üéØ –¢–ï–ú–ê –°–ö–ê–ó–ö–ò: {chosen_plot}{COLORS['ENDC']}\n")

CAMPBELL_STAGES = [
    "1. –û–±—ã—á–Ω—ã–π –º–∏—Ä",
    "2. –ü—Ä–∏–∑—ã–≤ –∫ –ø—Ä–∏–∫–ª—é—á–µ–Ω–∏—é",
    "3. –û—Ç–∫–∞–∑ –æ—Ç –ø—Ä–∏–∑—ã–≤–∞",
    "4. –í—Å—Ç—Ä–µ—á–∞ —Å –Ω–∞—Å—Ç–∞–≤–Ω–∏–∫–æ–º",
    "5. –ü–µ—Ä–µ—Ö–æ–¥ –ø–æ—Ä–æ–≥–∞",
    "6. –ò—Å–ø—ã—Ç–∞–Ω–∏—è, —Å–æ—é–∑–Ω–∏–∫–∏, –≤—Ä–∞–≥–∏",
    "7. –ü–æ–¥–∑–µ–º–µ–ª—å–µ: –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ –∫ –ø–µ—â–µ—Ä–µ",
    "8. –ö—É–ª—å–º–∏–Ω–∞—Ü–∏—è: –∏—Å–ø—ã—Ç–∞–Ω–∏–µ –æ–≥–Ω—ë–º",
    "9. –í–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ",
    "10. –í–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ —Å –¥–∞—Ä–æ–º"
]

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–æ–≤ ===
narrator = Agent("–†–∞—Å—Å–∫–∞–∑—á–∏–∫", "–¢—ã ‚Äî –≤–æ–ª—à–µ–±–Ω—ã–π —Ä–∞—Å—Å–∫–∞–∑—á–∏–∫. –ì–æ–≤–æ—Ä–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –≤ —Å—Ç–∏–ª–µ –Ω–∞—Ä–æ–¥–Ω–æ–π —Å–∫–∞–∑–∫–∏.")
child = Agent("–†–µ–±—ë–Ω–æ–∫", "–¢—ã ‚Äî —Ä–µ–±—ë–Ω–æ–∫ 7 –ª–µ—Ç. –†–µ–∞–≥–∏—Ä—É–π –ø–æ-—Ä—É—Å—Å–∫–∏: –∑–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å—ã, –ø—Ä–æ—Å–∏ –∏–∑–º–µ–Ω–∏—Ç—å.")
editor = Agent("–†–µ–¥–∞–∫—Ç–æ—Ä", "–¢—ã ‚Äî —Ä–µ–¥–∞–∫—Ç–æ—Ä. –ü—Ä–æ–≤–µ—Ä—è–π –ª–æ–≥–∏–∫—É —Å–∫–∞–∑–∫–∏.")

# === –•—Ä–∞–Ω–µ–Ω–∏–µ ===
history = []
full_tale = []
video_files = []


# === –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ===
def generate_image(prompt, filename="stage_image.png"):
    short_prompt = " ".join(prompt.split()[:70])  # –ü–µ—Ä–≤—ã–µ 70 —Å–ª–æ–≤
    full_prompt = (
        f"–ê–∫–≤–∞—Ä–µ–ª—å–Ω–∞—è –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—è –≤ —Å—Ç–∏–ª–µ –∏–º–ø—Ä–µ—Å—Å–∏–æ–Ω–∏–∑–º–∞, —Ä—É—Å—Å–∫–∞—è –Ω–∞—Ä–æ–¥–Ω–∞—è —Å–∫–∞–∑–∫–∞ ‚Äî {short_prompt}. "
        "Impressionist watercolor, dreamy light, Russian fairy tale, 4k"
    )
    image = pipe_sdxl(prompt=full_prompt, num_inference_steps=4, guidance_scale=0.0).images[0]

    os.makedirs("static", exist_ok=True)
    img_path = f"static/{filename}"
    image.save(img_path)

    print(f"üñºÔ∏è –ò–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞: {img_path}")

    # –í—ã–≤–æ–¥ –≤ Colab
    try:
        from IPython.display import display
        print("üñºÔ∏è –ü—Ä–æ—Å–º–æ—Ç—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:")
        display(image)
    except:
        pass

    return img_path


# === –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ ===
def generate_video(image_path, prompt, output_path="video.mp4"):
    if not args.generate_video:
        return None

    short_prompt = " ".join(prompt.split()[:70])
    image = Image.open(image_path).convert("RGB")
    image = image.resize((1024, 576))

    print(f"üé• –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ: {short_prompt[:60]}...")

    frames = pipe_svd(
        image,
        decode_chunk_size=8,
        generator=torch.manual_seed(42),
        motion_bucket_id=120,
        noise_aug_strength=0.02,
        num_frames=25,
        frame_rate=6
    ).frames[0]

    export_to_video(frames, output_path, fps=6)
    print(f"‚úÖ –í–∏–¥–µ–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")
    return output_path


# === –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª ===
for stage in CAMPBELL_STAGES:
    print(f"\n{'=' * 70}")
    print(f"{COLORS['–≠—Ç–∞–ø']}{stage.upper()}{COLORS['ENDC']}")
    print(f"{'=' * 70}")

    stage_prompt = f"–†–∞—Å—Å–∫–∞–∂–∏ —ç—Ç–∞–ø —Å–∫–∞–∑–∫–∏: {stage}. –¢–µ–º–∞: {chosen_plot}. –£—á—Ç–∏: {history[-2:] if history else '–Ω–∞—á–∞–ª–æ'}"
    tale_fragment = narrator.respond(stage_prompt)
    history.append({"role": "–†–∞—Å—Å–∫–∞–∑—á–∏–∫", "content": tale_fragment})
    full_tale.append(f"**{stage}**\n{tale_fragment}")

    # –î–∏–∞–ª–æ–≥
    print(f"\n{COLORS['–†–∞—Å—Å–∫–∞–∑—á–∏–∫']}üí¨ {tale_fragment}{COLORS['ENDC']}")

    child_resp = child.respond(f"–¢—ã —É—Å–ª—ã—à–∞–ª: {tale_fragment}...")
    print(f"\n{COLORS['–†–µ–±—ë–Ω–æ–∫']}üí¨ {child_resp}{COLORS['ENDC']}")

    editor_resp = editor.respond(f"–ü—Ä–æ–≤–µ—Ä—å –ª–æ–≥–∏–∫—É: {tale_fragment}")
    print(f"\n{COLORS['–†–µ–¥–∞–∫—Ç–æ—Ä']}üí¨ {editor_resp}{COLORS['ENDC']}")

    # –í—ã–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ –≥–ª–∞–≤—ã
    print(f"\n{COLORS['–°–∫–∞–∑–∫–∞']}üìñ –¢–ï–ö–°–¢ –°–ö–ê–ó–ö–ò:{COLORS['ENDC']}")
    print(f"{tale_fragment}\n")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ –≤—ã–≤–æ–¥ –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Å—Ä–∞–∑—É
    img_filename = f"stage_{CAMPBELL_STAGES.index(stage) + 1}.png"
    img_path = generate_image(tale_fragment, img_filename)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if args.generate_video:
        video_filename = f"video_stage_{CAMPBELL_STAGES.index(stage) + 1}.mp4"
        video_path = generate_video(img_path, tale_fragment, f"static/{video_filename}")
        if video_path:
            video_files.append(video_path)

# === –§–∏–Ω–∞–ª ===
print(f"\n{'=' * 70}")
print(f"{COLORS['–°–∫–∞–∑–∫–∞']}üìú –ü–û–õ–ù–ê–Ø –°–ö–ê–ó–ö–ê{COLORS['ENDC']}")
print(f"{'=' * 70}")

for part in full_tale:
    print(f"\n{part}\n")
    print(f"{'-' * 50}")

if args.generate_video:
    print(f"\n{COLORS['–í–∏–¥–µ–æ']}üé¨ –í–∏–¥–µ–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã:{COLORS['ENDC']}")
    for v in video_files:
        print(f"‚Üí {v}")